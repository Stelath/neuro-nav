{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import mne\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from braindecode import EEGRegressor\n",
    "from braindecode.preprocessing import preprocess, Preprocessor, exponential_moving_standardize\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset, create_from_X_y\n",
    "from braindecode.training.losses import CroppedLoss\n",
    "from braindecode.models import Deep4Net\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "from braindecode.util import set_random_seeds, create_mne_dummy_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(folder):\n",
    "    files = os.listdir(folder)\n",
    "    dataset = np.load(os.path.join(folder, files[0]), allow_pickle=True)\n",
    "    files.pop(0)\n",
    "    for file_path in files:\n",
    "        ds = np.load(os.path.join(folder, file_path), allow_pickle=True)\n",
    "        dataset[0] = np.concatenate((dataset[0], ds[0]), axis=0)\n",
    "        dataset[1] = np.concatenate((dataset[1], ds[1]), axis=0)\n",
    "    inputs = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = ['CP3', 'C3', 'F5', 'PO3', 'PO4', 'F6', 'C4', 'CP4']\n",
    "inputs, targets = load_dataset('data/train')\n",
    "inputs_val, targets_val = load_dataset('data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=8, n_times=1447\n",
      "    Range : 0 ... 1446 =      0.000 ...     5.648 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1248\n",
      "    Range : 0 ... 1247 =      0.000 ...     4.871 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1296\n",
      "    Range : 0 ... 1295 =      0.000 ...     5.059 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1008\n",
      "    Range : 0 ... 1007 =      0.000 ...     3.934 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1552\n",
      "    Range : 0 ... 1551 =      0.000 ...     6.059 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1272\n",
      "    Range : 0 ... 1271 =      0.000 ...     4.965 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1296\n",
      "    Range : 0 ... 1295 =      0.000 ...     5.059 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1256\n",
      "    Range : 0 ... 1255 =      0.000 ...     4.902 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1304\n",
      "    Range : 0 ... 1303 =      0.000 ...     5.090 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1272\n",
      "    Range : 0 ... 1271 =      0.000 ...     4.965 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1288\n",
      "    Range : 0 ... 1287 =      0.000 ...     5.027 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1288\n",
      "    Range : 0 ... 1287 =      0.000 ...     5.027 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1256\n",
      "    Range : 0 ... 1255 =      0.000 ...     4.902 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1264\n",
      "    Range : 0 ... 1263 =      0.000 ...     4.934 secs\n",
      "Ready.\n",
      "Using data from preloaded Raw for 3 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 3 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1447\n",
      "    Range : 0 ... 1446 =      0.000 ...     5.648 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1248\n",
      "    Range : 0 ... 1247 =      0.000 ...     4.871 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1296\n",
      "    Range : 0 ... 1295 =      0.000 ...     5.059 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1008\n",
      "    Range : 0 ... 1007 =      0.000 ...     3.934 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1552\n",
      "    Range : 0 ... 1551 =      0.000 ...     6.059 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1272\n",
      "    Range : 0 ... 1271 =      0.000 ...     4.965 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1296\n",
      "    Range : 0 ... 1295 =      0.000 ...     5.059 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1256\n",
      "    Range : 0 ... 1255 =      0.000 ...     4.902 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1304\n",
      "    Range : 0 ... 1303 =      0.000 ...     5.090 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1272\n",
      "    Range : 0 ... 1271 =      0.000 ...     4.965 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1288\n",
      "    Range : 0 ... 1287 =      0.000 ...     5.027 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1288\n",
      "    Range : 0 ... 1287 =      0.000 ...     5.027 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1256\n",
      "    Range : 0 ... 1255 =      0.000 ...     4.902 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1280\n",
      "    Range : 0 ... 1279 =      0.000 ...     4.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=1264\n",
      "    Range : 0 ... 1263 =      0.000 ...     4.934 secs\n",
      "Ready.\n",
      "Using data from preloaded Raw for 3 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 3 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 2 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target\n",
       "0        1\n",
       "1        0\n",
       "2        2\n",
       "3        1\n",
       "4        0\n",
       "5        2\n",
       "6        1\n",
       "7        0\n",
       "8        2\n",
       "9        1\n",
       "10       0\n",
       "11       2\n",
       "12       1\n",
       "13       0\n",
       "14       2\n",
       "15       1\n",
       "16       0\n",
       "17       2\n",
       "18       1\n",
       "19       0\n",
       "20       2\n",
       "21       1\n",
       "22       0\n",
       "23       2\n",
       "24       1\n",
       "25       0\n",
       "26       2\n",
       "27       1\n",
       "28       0\n",
       "29       2\n",
       "30       1\n",
       "31       0\n",
       "32       2\n",
       "33       1\n",
       "34       0\n",
       "35       2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_dataset = create_from_X_y(\n",
    "    inputs, targets, drop_last_window=False, sfreq=256, ch_names=ch_names,\n",
    "    window_stride_samples=392,\n",
    "    window_size_samples=1000,\n",
    ")\n",
    "\n",
    "emg_dataset_val = create_from_X_y(\n",
    "    inputs, targets, drop_last_window=False, sfreq=256, ch_names=ch_names,\n",
    "    window_stride_samples=392,\n",
    "    window_size_samples=1000,\n",
    ")\n",
    "\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "low_cut_hz = 4.  # low cut frequency for filtering\n",
    "high_cut_hz = 50.  # high cut frequency for filtering\n",
    "preprocessors = [\n",
    "    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "    # Preprocessor('notch_filter', freqs=60),\n",
    "    Preprocessor('filter_data', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "    # Preprocessor(exponential_moving_standardize,  # Exponential moving standardization\n",
    "    #              factor_new=factor_new, init_block_size=init_block_size)\n",
    "]\n",
    "\n",
    "# Transform the data\n",
    "# preprocess(emg_dataset[0], preprocessors)\n",
    "# preprocess(emg_dataset_val, preprocessors)\n",
    "\n",
    "emg_dataset.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stelath/miniconda3/envs/neuronav/lib/python3.8/site-packages/braindecode/util.py:51: UserWarning: torch.backends.cudnn.benchmark was set to True which may results in lack of reproducibility. In some cases to ensure reproducibility you may need to set torch.backends.cudnn.benchmark to False.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n",
      "Using data from preloaded Raw for 1 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 1000 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stelath/miniconda3/envs/neuronav/lib/python3.8/site-packages/braindecode/training/losses.py:32: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return self.loss_function(avg_preds, targets)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(n_preds_per_input)\n\u001b[1;32m     62\u001b[0m regressor \u001b[39m=\u001b[39m EEGRegressor(\n\u001b[1;32m     63\u001b[0m     model,\n\u001b[1;32m     64\u001b[0m     cropped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m     79\u001b[0m )\n\u001b[0;32m---> 81\u001b[0m regressor\u001b[39m.\u001b[39;49mfit(emg_dataset, y\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, epochs\u001b[39m=\u001b[39;49mn_epochs)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/braindecode/regressor.py:318\u001b[0m, in \u001b[0;36mEEGRegressor.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    317\u001b[0m         y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 318\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/regressor.py:91\u001b[0m, in \u001b[0;36mNeuralNetRegressor.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[39mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m# this is actually a pylint bug:\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(NeuralNetRegressor, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:1230\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized_:\n\u001b[1;32m   1228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n\u001b[0;32m-> 1230\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:1189\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_train_begin\u001b[39m\u001b[39m'\u001b[39m, X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my)\n\u001b[1;32m   1188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:1101\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m   1099\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_epoch_begin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single_epoch(iterator_train, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1102\u001b[0m                           step_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single_epoch(iterator_valid, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1105\u001b[0m                           step_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m   1107\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_epoch_end\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:1137\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[0;34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_batch_begin\u001b[39m\u001b[39m\"\u001b[39m, batch\u001b[39m=\u001b[39mbatch, training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m-> 1137\u001b[0m     step \u001b[39m=\u001b[39m step_fn(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mrecord_batch(prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m, step[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem())\n\u001b[1;32m   1139\u001b[0m     batch_size \u001b[39m=\u001b[39m (get_len(batch[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(batch, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))\n\u001b[1;32m   1140\u001b[0m                   \u001b[39melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:1016\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[1;32m   1010\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1011\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1012\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m     \u001b[39mreturn\u001b[39;00m step[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 1016\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_optimizer(step_fn)\n\u001b[1;32m   1017\u001b[0m \u001b[39mreturn\u001b[39;00m step_accumulator\u001b[39m.\u001b[39mget_step()\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:972\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[0;34m(self, step_fn)\u001b[0m\n\u001b[1;32m    970\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(step_fn)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/torch/optim/adamw.py:120\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 120\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    122\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    123\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:1006\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_fn\u001b[39m():\n\u001b[1;32m   1005\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_optimizer()\n\u001b[0;32m-> 1006\u001b[0m     step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step_single(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1007\u001b[0m     step_accumulator\u001b[39m.\u001b[39mstore_step(step)\n\u001b[1;32m   1009\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[1;32m   1010\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1011\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1012\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[1;32m   1013\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:906\u001b[0m, in \u001b[0;36mNeuralNet.train_step_single\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m    904\u001b[0m Xi, yi \u001b[39m=\u001b[39m unpack_data(batch)\n\u001b[1;32m    905\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(Xi, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 906\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_loss(y_pred, yi, X\u001b[39m=\u001b[39;49mXi, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    907\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    908\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    909\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: loss,\n\u001b[1;32m    910\u001b[0m     \u001b[39m'\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m'\u001b[39m: y_pred,\n\u001b[1;32m    911\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/braindecode/regressor.py:152\u001b[0m, in \u001b[0;36mEEGRegressor.get_loss\u001b[0;34m(self, y_pred, y_true, *args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_loss\u001b[39m(\u001b[39mself\u001b[39m, y_pred, y_true, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    123\u001b[0m     \u001b[39m\"\"\"Return the loss for this batch by calling NeuralNet get_loss.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m        The loss value.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m NeuralNet\u001b[39m.\u001b[39;49mget_loss(\u001b[39mself\u001b[39;49m, y_pred, y_true, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/skorch/net.py:1571\u001b[0m, in \u001b[0;36mNeuralNet.get_loss\u001b[0;34m(self, y_pred, y_true, X, training)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[39m\"\"\"Return the loss for this batch.\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \n\u001b[1;32m   1544\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \n\u001b[1;32m   1569\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m y_true \u001b[39m=\u001b[39m to_tensor(y_true, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1571\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion_(y_pred, y_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/braindecode/training/losses.py:32\u001b[0m, in \u001b[0;36mCroppedLoss.forward\u001b[0;34m(self, preds, targets)\u001b[0m\n\u001b[1;32m     30\u001b[0m avg_preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(preds, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     31\u001b[0m avg_preds \u001b[39m=\u001b[39m avg_preds\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_function(avg_preds, targets)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/torch/nn/functional.py:3291\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3289\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3291\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[1;32m   3292\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/envs/neuronav/lib/python3.8/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model_name = \"shallow\"  # 'shallow' or 'deep'\n",
    "n_epochs = 30\n",
    "seed = 20200220\n",
    "\n",
    "input_window_samples = 1000\n",
    "batch_size = 3\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "n_chans = 8\n",
    "# set to how many targets you want to regress (age -> 1, [x, y, z] -> 3)\n",
    "n_classes = 3\n",
    "\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "# initialize a model, transform to dense and move to gpu\n",
    "if model_name == \"shallow\":\n",
    "    model = ShallowFBCSPNet(\n",
    "        in_chans=n_chans,\n",
    "        n_classes=n_classes,\n",
    "        input_window_samples=input_window_samples,\n",
    "        n_filters_time=40,\n",
    "        n_filters_spat=40,\n",
    "        final_conv_length=35,\n",
    "    )\n",
    "    optimizer_lr = 0.000625\n",
    "    optimizer_weight_decay = 0\n",
    "elif model_name == \"deep\":\n",
    "    model = Deep4Net(\n",
    "        in_chans=n_chans,\n",
    "        n_classes=n_classes,\n",
    "        input_window_samples=input_window_samples,\n",
    "        n_filters_time=25,\n",
    "        n_filters_spat=25,\n",
    "        stride_before_pool=True,\n",
    "        n_filters_2=int(n_chans * 2),\n",
    "        n_filters_3=int(n_chans * (2 ** 2.0)),\n",
    "        n_filters_4=int(n_chans * (2 ** 3.0)),\n",
    "        final_conv_length=1,\n",
    "    )\n",
    "    optimizer_lr = 0.01\n",
    "    optimizer_weight_decay = 0.0005\n",
    "else:\n",
    "    raise ValueError(f'{model_name} unknown')\n",
    "\n",
    "new_model = torch.nn.Sequential()\n",
    "for name, module_ in model.named_children():\n",
    "    if \"softmax\" in name:\n",
    "        continue\n",
    "    new_model.add_module(name, module_)\n",
    "model = new_model\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "to_dense_prediction_model(model)\n",
    "n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]\n",
    "print(n_preds_per_input)\n",
    "\n",
    "regressor = EEGRegressor(\n",
    "    model,\n",
    "    cropped=True,\n",
    "    criterion=CroppedLoss,\n",
    "    criterion__loss_function=torch.nn.functional.mse_loss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(emg_dataset_val),\n",
    "    optimizer__lr=optimizer_lr,\n",
    "    optimizer__weight_decay=optimizer_weight_decay,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"neg_root_mean_squared_error\",\n",
    "        # seems n_epochs -1 leads to desired behavior of lr=0 after end of training?\n",
    "        (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "regressor.fit(emg_dataset, y=None, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuronav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d5aef1c97cce0d8b1b8135a3f65fe22a8049f381bd703d7f19d42d052a45954"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
